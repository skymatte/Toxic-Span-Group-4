{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Evaluation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jutgPsZHRPeN"
      },
      "source": [
        "# Lint as: python3\n",
        "\"\"\"Example tagging for Toxic Spans based on Spacy.\n",
        "Requires:\n",
        "  pip install spacy sklearn\n",
        "Install models:\n",
        "  python -m spacy download en_core_web_sm\n",
        "\"\"\"\n",
        "\n",
        "import ast\n",
        "import csv\n",
        "import random\n",
        "import statistics\n",
        "import sys\n",
        "\n",
        "import sklearn\n",
        "import spacy\n",
        "\n",
        "sys.path.append('../evaluation')\n",
        "# import semeval2021\n",
        "# import fix_spans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEIgxPyvt-np"
      },
      "source": [
        "def _contiguous_ranges(span_list):\n",
        "    \"\"\"Extracts continguous runs [1, 2, 3, 5, 6, 7] -> [(1,3), (5,7)].\"\"\"\n",
        "    output = []\n",
        "    for _, span in itertools.groupby(\n",
        "        enumerate(span_list), lambda p: p[1] - p[0]):\n",
        "        span = list(span)\n",
        "        output.append((span[0][1], span[-1][1]))\n",
        "    return output\n",
        "\n",
        "import ast\n",
        "import csv\n",
        "import itertools\n",
        "import string\n",
        "import sys\n",
        "\n",
        "SPECIAL_CHARACTERS = string.whitespace\n",
        "def fix_spans(spans, text, special_characters=SPECIAL_CHARACTERS):\n",
        "    \"\"\"Applies minor edits to trim spans and remove singletons.\"\"\"\n",
        "    cleaned = []\n",
        "    for begin, end in _contiguous_ranges(spans):\n",
        "        while text[begin] in special_characters and begin < end:\n",
        "            begin += 1\n",
        "        while text[end] in special_characters and begin < end:\n",
        "            end -= 1\n",
        "        if end - begin > 1:\n",
        "            cleaned.extend(range(begin, end + 1))\n",
        "    return cleaned"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Hq0kZ7FuCnS"
      },
      "source": [
        "def read_datafile(filename):\n",
        "  \"\"\"Reads csv file with python span list and text.\"\"\"\n",
        "  data = []\n",
        "  with open(filename) as csvfile:\n",
        "    reader = csv.DictReader(csvfile)\n",
        "    count = 0\n",
        "    for row in reader:\n",
        "      fixed = fix_spans(\n",
        "          ast.literal_eval(row['spans']), row['text'])\n",
        "      data.append((fixed, row['text']))\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK2346e-uGLm"
      },
      "source": [
        "def f1(predictions, gold):\n",
        "    \"\"\"\n",
        "    F1 (a.k.a. DICE) operating on two lists of offsets (e.g., character).\n",
        "    >>> assert f1([0, 1, 4, 5], [0, 1, 6]) == 0.5714285714285714\n",
        "    :param predictions: a list of predicted offsets\n",
        "    :param gold: a list of offsets serving as the ground truth\n",
        "    :return: a score between 0 and 1\n",
        "    \"\"\"\n",
        "    if len(gold) == 0:\n",
        "        return 1. if len(predictions) == 0 else 0.\n",
        "    if len(predictions) == 0:\n",
        "        return 0.\n",
        "    predictions_set = set(predictions)\n",
        "    gold_set = set(gold)\n",
        "    nom = 2 * len(predictions_set.intersection(gold_set))\n",
        "    denom = len(predictions_set) + len(gold_set)\n",
        "    return float(nom)/float(denom)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmGVMgAlulY5",
        "outputId": "e6cf3495-29c5-4d2d-9bcb-625b298ad714"
      },
      "source": [
        "print('loading actual data')\n",
        "act = read_datafile('/content/drive/MyDrive/Submission/devfinal.csv')\n",
        "\n",
        "print('loading predictions data')\n",
        "res = read_datafile('/content/drive/MyDrive/Submission/pred.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading actual data\n",
            "loading predictions data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFJWyPlq3pw-",
        "outputId": "d1816752-98ea-4378-f78e-0552bbb89769"
      },
      "source": [
        "print('evaluation')\n",
        "scores = []\n",
        "\n",
        "for i in range(len(act)):\n",
        "  pred = res[i][0]\n",
        "  span = act[i][0]\n",
        "\n",
        "  score = f1(pred, span)\n",
        "  scores.append(score)\n",
        "\n",
        "print('avg F1 %g' % statistics.mean(scores))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "evaluation\n",
            "avg F1 0.618362\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRqKvCxzjyef"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}